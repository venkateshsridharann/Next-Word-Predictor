{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49daf8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66e2eede",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1000000</td>\n",
       "      <td>1000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>949636</td>\n",
       "      <td>949636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Why?</td>\n",
       "      <td>Why?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>259</td>\n",
       "      <td>259</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          title    clean\n",
       "count   1000000  1000000\n",
       "unique   949636   949636\n",
       "top        Why?     Why?\n",
       "freq        259      259"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "medium_data = pd.read_csv('questions.csv')\n",
    "medium_data['clean'] = medium_data['title']\n",
    "medium_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09b1ead5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records:  1000000\n",
      "Number of fields:  2\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of records: \", medium_data.shape[0])\n",
    "print(\"Number of fields: \", medium_data.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c159cfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          What's the ugliest word in the English language?\n",
       "1         If you could bring one celebrity back from the...\n",
       "2         The year is 2022. We've now discover how time ...\n",
       "3                           What's your unpopular opinions?\n",
       "4                         Celebrities with the biggest ego?\n",
       "                                ...                        \n",
       "999995    Is it true that, â€œIf you don't use it, you los...\n",
       "999996                 What is your favorite drive-through?\n",
       "999997    (SERIOUS) WHAT'S A SFW WAY TO EXPLAIN THE AHEA...\n",
       "999998    Will you see this post https://www.reddit.com/...\n",
       "999999                What do you hope your last words are?\n",
       "Name: title, Length: 1000000, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "medium_data['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41da656f",
   "metadata": {},
   "outputs": [],
   "source": [
    "medium_data['title'] = medium_data['title'].apply(lambda x: x.replace(u'\\xa0',u' '))\n",
    "medium_data['title'] = medium_data['title'].apply(lambda x: x.replace('\\u200a',' '))\n",
    "medium_data['title'] = [x.lower() for x in medium_data['title']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "898bd7ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         what's the ugliest word in the english language?\n",
       "1        if you could bring one celebrity back from the...\n",
       "2        the year is 2022. we've now discover how time ...\n",
       "3                          what's your unpopular opinions?\n",
       "4                        celebrities with the biggest ego?\n",
       "                               ...                        \n",
       "19995    for the next 24 hours, anyone you want to have...\n",
       "19996    why do some people who don't want kids still g...\n",
       "19997    you go to a job interview and have a minute to...\n",
       "19998          what's something that annoys you on reddit?\n",
       "19999    which song makes you drive real fast that the ...\n",
       "Name: title, Length: 20000, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions = medium_data['title'][:20000]\n",
    "questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ff2bd51",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tokenizer = Tokenizer(oov_token='<oov>') # For those words which are not found in word_index\n",
    "tokenizer.fit_on_texts(questions)\n",
    "total_words = len(tokenizer.word_index) + 1\n",
    "\n",
    "# print(\"Total number of words: \", total_words)\n",
    "# print(\"Word: ID\")\n",
    "# print(\"------------\")\n",
    "# print(\"<oov>: \", tokenizer.word_index['<oov>'])\n",
    "# print(\"Strong: \", tokenizer.word_index['strong'])\n",
    "# print(\"And: \", tokenizer.word_index['and'])\n",
    "# print(\"Consumption: \", tokenizer.word_index['consumption'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9994f3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total input sequences:  262584\n"
     ]
    }
   ],
   "source": [
    "input_sequences = []\n",
    "for line in questions:\n",
    "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "    #print(token_list)\n",
    "    \n",
    "    for i in range(1, len(token_list)):\n",
    "        n_gram_sequence = token_list[:i+1]\n",
    "        input_sequences.append(n_gram_sequence)\n",
    "\n",
    "# print(input_sequences)\n",
    "print(\"Total input sequences: \", len(input_sequences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "66ae0f0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,   18,    4,\n",
       "       8385])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pad sequences \n",
    "max_sequence_len = max([len(x) for x in input_sequences])\n",
    "input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
    "input_sequences[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c4a531d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create features and label\n",
    "xs, labels = input_sequences[:,:-1],input_sequences[:,-1]\n",
    "ys = tf.keras.utils.to_categorical(labels, num_classes=total_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "34e5922f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0   18    4 8385  218   12    4]\n",
      "484\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(xs[5])\n",
    "print(labels[5])\n",
    "print(ys[5][14])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751e4174",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "8206/8206 [==============================] - 1833s 223ms/step - loss: 5.8464 - accuracy: 0.1441\n",
      "Epoch 2/40\n",
      "8206/8206 [==============================] - 1844s 225ms/step - loss: 5.0186 - accuracy: 0.2025\n",
      "Epoch 3/40\n",
      "8206/8206 [==============================] - 1816s 221ms/step - loss: 4.6040 - accuracy: 0.2306\n",
      "Epoch 4/40\n",
      "8206/8206 [==============================] - 1868s 228ms/step - loss: 4.2644 - accuracy: 0.2570\n",
      "Epoch 5/40\n",
      "8206/8206 [==============================] - 1790s 218ms/step - loss: 3.9707 - accuracy: 0.2820\n",
      "Epoch 6/40\n",
      "8206/8206 [==============================] - 1829s 223ms/step - loss: 3.7179 - accuracy: 0.3074\n",
      "Epoch 7/40\n",
      "8206/8206 [==============================] - 1995s 243ms/step - loss: 3.4938 - accuracy: 0.3324\n",
      "Epoch 8/40\n",
      "8206/8206 [==============================] - 2021s 246ms/step - loss: 3.2950 - accuracy: 0.3578\n",
      "Epoch 9/40\n",
      "8206/8206 [==============================] - 3066s 374ms/step - loss: 3.1177 - accuracy: 0.3815\n",
      "Epoch 10/40\n",
      "8206/8206 [==============================] - 2383s 290ms/step - loss: 2.9595 - accuracy: 0.4051\n",
      "Epoch 11/40\n",
      "8206/8206 [==============================] - 2142s 261ms/step - loss: 2.8191 - accuracy: 0.4261\n",
      "Epoch 12/40\n",
      "4066/8206 [=============>................] - ETA: 17:04 - loss: 2.5744 - accuracy: 0.4638"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(total_words, 100, input_length=max_sequence_len-1))\n",
    "model.add(Bidirectional(LSTM(150)))\n",
    "model.add(Dense(total_words, activation='softmax'))\n",
    "adam = Adam(lr=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "history = model.fit(xs, ys, epochs=40, verbose=1)\n",
    "#print model.summary()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8a0ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"next_word_try_3_1.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a99154",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_graphs(history, string):\n",
    "    plt.plot(history.history[string])\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(string)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8485ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_graphs(history, 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c45213",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_graphs(history, 'loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83292870",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"next_word_try_3_1.keras\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "39f5ab15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "let me ask you why or why not\n"
     ]
    }
   ],
   "source": [
    "seed_text = \"let me ask you why\"\n",
    "next_words = 3\n",
    "  \n",
    "for _ in range(next_words):\n",
    "    token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "    token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "#     predicted = model.predict_classes(token_list, verbose=0)\n",
    "    predicted=model.predict(token_list,verbose=0) \n",
    "    predicted=np.argmax(predicted,axis=1)\n",
    "    output_word = \"\"\n",
    "    for word, index in tokenizer.word_index.items():\n",
    "        if index == predicted:\n",
    "            output_word = word\n",
    "            break\n",
    "    seed_text += \" \" + output_word\n",
    "print(seed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "90661376",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict only next word\n",
    "def predict_next(seed_text):\n",
    "    token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "    token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "#     predicted = model.predict_classes(token_list, verbose=0)\n",
    "    predicted=model.predict(token_list,verbose=0) \n",
    "    predicted=np.argmax(predicted,axis=1)\n",
    "    output_word = \"\"\n",
    "    for word, index in tokenizer.word_index.items():\n",
    "        if index == predicted:\n",
    "            output_word = word\n",
    "            break\n",
    "    seed_text += \" \" + output_word\n",
    "    return seed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4a7d13cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input</th>\n",
       "      <th>Output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>will AI become</td>\n",
       "      <td>will AI become smarter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>why does it seem</td>\n",
       "      <td>why does it seem to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>is it the right way to</td>\n",
       "      <td>is it the right way to get</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Recipe of my</td>\n",
       "      <td>Recipe of my own</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I am going to</td>\n",
       "      <td>I am going to raise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>will this work</td>\n",
       "      <td>will this work against</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Input                      Output\n",
       "0          will AI become      will AI become smarter\n",
       "1        why does it seem         why does it seem to\n",
       "2  is it the right way to  is it the right way to get\n",
       "3            Recipe of my            Recipe of my own\n",
       "4           I am going to         I am going to raise\n",
       "5          will this work      will this work against"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_input = [\"will AI become\", \"why does it seem\", \"is it the right way to\",\"Recipe of my\",\"I am going to\",\"will this work\"]\n",
    "list_out = []\n",
    "\n",
    "for seed_text in list_input:\n",
    "    list_out.append(predict_next(seed_text))\n",
    "\n",
    "dict = {'Input':list_input,\n",
    "        'Output':list_out}\n",
    "\n",
    "df = pd.DataFrame(dict)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "420874ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input</th>\n",
       "      <th>Output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>will AI become</td>\n",
       "      <td>will AI become a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>why does it seem</td>\n",
       "      <td>why does it seem to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>is it the right way to</td>\n",
       "      <td>is it the right way to be</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Recipe of my</td>\n",
       "      <td>Recipe of my opinion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I am going to</td>\n",
       "      <td>I am going to be</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>will this work</td>\n",
       "      <td>will this work be</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Input                     Output\n",
       "0          will AI become           will AI become a\n",
       "1        why does it seem        why does it seem to\n",
       "2  is it the right way to  is it the right way to be\n",
       "3            Recipe of my       Recipe of my opinion\n",
       "4           I am going to           I am going to be\n",
       "5          will this work          will this work be"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_input = [\"will AI become\", \"why does it seem\", \"is it the right way to\",\"Recipe of my\",\"I am going to\",\"will this work\"]\n",
    "list_out = []\n",
    "\n",
    "for seed_text in list_input:\n",
    "    list_out.append(predict_next(seed_text))\n",
    "\n",
    "dict = {'Input':list_input,\n",
    "        'Output':list_out}\n",
    "\n",
    "df = pd.DataFrame(dict)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "62800504",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input</th>\n",
       "      <th>prediction 1</th>\n",
       "      <th>prediction 2</th>\n",
       "      <th>prediction 3</th>\n",
       "      <th>Output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>will AI become</td>\n",
       "      <td>smarter (0.308)</td>\n",
       "      <td>an (0.237)</td>\n",
       "      <td>a (0.176)</td>\n",
       "      <td>will AI become smarter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>why does it seem</td>\n",
       "      <td>to (1.0)</td>\n",
       "      <td>and (0.0)</td>\n",
       "      <td>can (0.0)</td>\n",
       "      <td>why does it seem to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>is it the right way to</td>\n",
       "      <td>get (0.272)</td>\n",
       "      <td>goals (0.171)</td>\n",
       "      <td>heart (0.129)</td>\n",
       "      <td>is it the right way to get</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Recipe of my</td>\n",
       "      <td>own (0.539)</td>\n",
       "      <td>python (0.104)</td>\n",
       "      <td>pipeline (0.087)</td>\n",
       "      <td>Recipe of my own</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I am going to</td>\n",
       "      <td>raise (0.171)</td>\n",
       "      <td>keep (0.133)</td>\n",
       "      <td>find (0.129)</td>\n",
       "      <td>I am going to raise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>will this work</td>\n",
       "      <td>against (0.433)</td>\n",
       "      <td>from (0.291)</td>\n",
       "      <td>after (0.07)</td>\n",
       "      <td>will this work against</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Am I on the right</td>\n",
       "      <td>time (0.671)</td>\n",
       "      <td>way (0.25)</td>\n",
       "      <td>tech (0.023)</td>\n",
       "      <td>Am I on the right time</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Input     prediction 1    prediction 2      prediction 3  \\\n",
       "0          will AI become  smarter (0.308)      an (0.237)         a (0.176)   \n",
       "1        why does it seem         to (1.0)       and (0.0)         can (0.0)   \n",
       "2  is it the right way to      get (0.272)   goals (0.171)     heart (0.129)   \n",
       "3            Recipe of my      own (0.539)  python (0.104)  pipeline (0.087)   \n",
       "4           I am going to    raise (0.171)    keep (0.133)      find (0.129)   \n",
       "5          will this work  against (0.433)    from (0.291)      after (0.07)   \n",
       "6       Am I on the right     time (0.671)      way (0.25)      tech (0.023)   \n",
       "\n",
       "                       Output  \n",
       "0      will AI become smarter  \n",
       "1         why does it seem to  \n",
       "2  is it the right way to get  \n",
       "3            Recipe of my own  \n",
       "4         I am going to raise  \n",
       "5      will this work against  \n",
       "6      Am I on the right time  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_input = [\"will AI become\", \"why does it seem\", \"is it the right way to\",\"Recipe of my\",\"I am going to\",\"will this work\",\"Am I on the right\"]\n",
    "\n",
    "predictions = [[],[],[]]\n",
    "\n",
    "list_output = []\n",
    "\n",
    "next_words = 1\n",
    "for seed_text in list_input:\n",
    "    for _ in range(next_words):\n",
    "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "        token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "\n",
    "        # Predict probabilities for all words\n",
    "        predicted_probabilities = model.predict(token_list, verbose=0)[0]\n",
    "\n",
    "        # Get the indices of the top 3 predicted words\n",
    "        top3_word_indices = np.argsort(predicted_probabilities)[-3:][::-1]\n",
    "\n",
    "        # Get the top 3 words and their probabilities\n",
    "        top3_words = [tokenizer.index_word[idx] for idx in top3_word_indices]\n",
    "        top3_probabilities = [round(predicted_probabilities[idx],3) for idx in top3_word_indices]\n",
    "\n",
    "        for i in range(len(top3_words)):\n",
    "            o = str(top3_words[i])+\" (\"+str(top3_probabilities[i])+\")\"\n",
    "            predictions[i].append(o)\n",
    "                    \n",
    "#         # Print the top 3 suggestions\n",
    "#         print(\"Top 3 Predictions:\")\n",
    "#         for word, prob in zip(top3_words, top3_probabilities):\n",
    "#             print(f\"{word}: {prob:.4f}\")\n",
    "\n",
    "        # Choose the word with the highest probability as the next word\n",
    "        output_word = top3_words[0]\n",
    "        seed_text += \" \" + output_word\n",
    "        list_output.append(seed_text)\n",
    "        \n",
    "        \n",
    "dict = {'Input':list_input,\n",
    "        'prediction 1':predictions[0],\n",
    "        'prediction 2':predictions[1],\n",
    "        'prediction 3':predictions[2],\n",
    "        'Output':list_output,}    \n",
    "\n",
    "df = pd.DataFrame(dict)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c1180a80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input</th>\n",
       "      <th>prediction 1</th>\n",
       "      <th>prediction 2</th>\n",
       "      <th>prediction 3</th>\n",
       "      <th>Output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>will AI become</td>\n",
       "      <td>a (0.184)</td>\n",
       "      <td>the (0.055)</td>\n",
       "      <td>an (0.024)</td>\n",
       "      <td>will AI become a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>why does it seem</td>\n",
       "      <td>to (0.717)</td>\n",
       "      <td>like (0.032)</td>\n",
       "      <td>about (0.024)</td>\n",
       "      <td>why does it seem to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>is it the right way to</td>\n",
       "      <td>be (0.09)</td>\n",
       "      <td>get (0.072)</td>\n",
       "      <td>make (0.041)</td>\n",
       "      <td>is it the right way to be</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Recipe of my</td>\n",
       "      <td>opinion (0.028)</td>\n",
       "      <td>own (0.027)</td>\n",
       "      <td>life (0.018)</td>\n",
       "      <td>Recipe of my opinion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I am going to</td>\n",
       "      <td>be (0.056)</td>\n",
       "      <td>help (0.044)</td>\n",
       "      <td>get (0.031)</td>\n",
       "      <td>I am going to be</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>will this work</td>\n",
       "      <td>be (0.336)</td>\n",
       "      <td>like (0.015)</td>\n",
       "      <td>help (0.014)</td>\n",
       "      <td>will this work be</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Am I on the right</td>\n",
       "      <td>i (0.036)</td>\n",
       "      <td>now (0.034)</td>\n",
       "      <td>and (0.032)</td>\n",
       "      <td>Am I on the right i</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Input     prediction 1  prediction 2   prediction 3  \\\n",
       "0          will AI become        a (0.184)   the (0.055)     an (0.024)   \n",
       "1        why does it seem       to (0.717)  like (0.032)  about (0.024)   \n",
       "2  is it the right way to        be (0.09)   get (0.072)   make (0.041)   \n",
       "3            Recipe of my  opinion (0.028)   own (0.027)   life (0.018)   \n",
       "4           I am going to       be (0.056)  help (0.044)    get (0.031)   \n",
       "5          will this work       be (0.336)  like (0.015)   help (0.014)   \n",
       "6       Am I on the right        i (0.036)   now (0.034)    and (0.032)   \n",
       "\n",
       "                      Output  \n",
       "0           will AI become a  \n",
       "1        why does it seem to  \n",
       "2  is it the right way to be  \n",
       "3       Recipe of my opinion  \n",
       "4           I am going to be  \n",
       "5          will this work be  \n",
       "6        Am I on the right i  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_input = [\"will AI become\", \"why does it seem\", \"is it the right way to\",\"Recipe of my\",\"I am going to\",\"will this work\",\"Am I on the right\"]\n",
    "\n",
    "predictions = [[],[],[]]\n",
    "\n",
    "list_output = []\n",
    "\n",
    "next_words = 1\n",
    "for seed_text in list_input:\n",
    "    for _ in range(next_words):\n",
    "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "        token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "\n",
    "        # Predict probabilities for all words\n",
    "        predicted_probabilities = model.predict(token_list, verbose=0)[0]\n",
    "\n",
    "        # Get the indices of the top 3 predicted words\n",
    "        top3_word_indices = np.argsort(predicted_probabilities)[-3:][::-1]\n",
    "\n",
    "        # Get the top 3 words and their probabilities\n",
    "        top3_words = [tokenizer.index_word[idx] for idx in top3_word_indices]\n",
    "        top3_probabilities = [round(predicted_probabilities[idx],3) for idx in top3_word_indices]\n",
    "\n",
    "        for i in range(len(top3_words)):\n",
    "            o = str(top3_words[i])+\" (\"+str(top3_probabilities[i])+\")\"\n",
    "            predictions[i].append(o)\n",
    "                    \n",
    "#         # Print the top 3 suggestions\n",
    "#         print(\"Top 3 Predictions:\")\n",
    "#         for word, prob in zip(top3_words, top3_probabilities):\n",
    "#             print(f\"{word}: {prob:.4f}\")\n",
    "\n",
    "        # Choose the word with the highest probability as the next word\n",
    "        output_word = top3_words[0]\n",
    "        seed_text += \" \" + output_word\n",
    "        list_output.append(seed_text)\n",
    "        \n",
    "        \n",
    "dict = {'Input':list_input,\n",
    "        'prediction 1':predictions[0],\n",
    "        'prediction 2':predictions[1],\n",
    "        'prediction 3':predictions[2],\n",
    "        'Output':list_output,}    \n",
    "\n",
    "df = pd.DataFrame(dict)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97c1ba50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the tokenizer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "medium_data = pd.read_csv('questions.csv')\n",
    "medium_data['title'] = medium_data['title'].apply(lambda x: x.replace(u'\\xa0',u' '))\n",
    "medium_data['title'] = medium_data['title'].apply(lambda x: x.replace('\\u200a',' '))\n",
    "\n",
    "tokenizer = Tokenizer(oov_token='<oov>')  # For those words which are not found in word_index\n",
    "tokenizer.fit_on_texts(medium_data['title'])\n",
    "\n",
    "# Save the trained tokenizer\n",
    "with open(\"tokenizer.pickle\", \"wb\") as handle:\n",
    "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6975f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nwpredictor",
   "language": "python",
   "name": "nwpredictor"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
